---
apiVersion: batch/v1
kind: Job
metadata:
  name: create-bucket-job
  namespace: mlops-workshop
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  backoffLimit: 4
  template:
    spec:
      containers:
      - name: upload-training-data-to-bucket
        image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:1.2
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash"]
        args:
        - -ec
        - |-
          curl -LO https://github.com/JuanmaBM/mlops-workshop/blob/main/training-data/data.zip\?raw\=true
          curl -LO https://github.com/JuanmaBM/mlops-workshop/blob/main/training-data/test.zip\?raw\=true
          cat << 'EOF' | python3
          import boto3, os
          s3 = boto3.client("s3",
                            endpoint_url=os.getenv("AWS_S3_ENDPOINT"),
                            aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
                            aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"))
          bucket = os.getenv("AWS_S3_BUCKET")
          if bucket not in [bu["Name"] for bu in s3.list_buckets()["Buckets"]]:
            s3.create_bucket(Bucket=bucket)
          s3.upload_file('data.zip', bucket, 'dataset/data.zip')
          s3.upload_file('test.zip', bucket, 'dataset/test.zip')
          EOF
        envFrom:
        - secretRef:
            name: aws-connection-mlops-workshop-bucket
      restartPolicy: Never